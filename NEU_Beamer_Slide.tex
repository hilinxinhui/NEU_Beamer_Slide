\documentclass[10pt,aspectratio=43,mathserif]{beamer}		
%设置为 Beamer 文档类型，设置字体为 10pt，长宽比为16:9，数学字体为 serif 风格

%%%%-----导入宏包-----%%%%
\usepackage{neu}
\usepackage{xeCJK}
\usepackage{amsmath,amsfonts,amssymb,bm}
\usepackage{color}
\usepackage{graphicx,hyperref,url}
\usepackage{latexsym,amsmath,xcolor,multicol,booktabs,calligra}
\usepackage{graphicx,pstricks,listings,stackengine}
%%%%%%%%%%%%%%%%%%

\definecolor{neu_blue}{RGB}{42,69,140}

%%%%-----设置字体-----%%%%
%Windows和Mac OS下都可用
% \setsansfont[Path=fonts/]{Helvetica}

\setsansfont{Times New Roman}
\setCJKmainfont{Songti SC}

\beamertemplateballitem
\def\cmd#1{\texttt{\color{red}\footnotesize $\backslash$#1}}
\def\env#1{\texttt{\color{blue}\footnotesize #1}}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}
\definecolor{halfgray}{gray}{0.55}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=red,
    citecolor=blue
}

\usepackage[backend=biber,style=numeric,sorting=none]{biblatex}
\addbibresource{./ref.bib} %BibTeX数据文件及位置
\setbeamerfont{footnote}{size=\tiny} %调整注脚的文字大小

\lstset{
    basicstyle=\ttfamily\small,
    keywordstyle=\bfseries\color{deepblue},
    emphstyle=\ttfamily\color{deepred},    % Custom highlighting style
    stringstyle=\color{deepgreen},
    numbers=left,
    numberstyle=\small\color{halfgray},
    rulesepcolor=\color{red!20!green!20!blue!20},
    frame=shadowbox,
}

%%%%----首页信息设置----%%%%
\title[汇报]{\fontsize{13pt}{18pt}\selectfont {汇报}}
%%%%----标题设置

\author[林新辉]{林新辉 \\\medskip}
%%%%----个人信息设置

\date[\today]{
 \today}
%%%%----日期

\begin{document}

% 标题页
\begin{frame}
  \titlepage
\end{frame}

% 目录页
\section*{目录}
\begin{frame}
  \frametitle{\textbf{目录}}
  \textbf{\tableofcontents}
\end{frame}

\section{文献阅读}

\begin{frame}
  \begin{itemize}
    \item 经典论文回顾
    \footnote{Krizhevsky, A., Sutskever, I., \& Hinton, G. E.. Imagenet classification with deep convolutional neural networks. 2012. NIPS.}
    \footnote{He, K., Zhang, X., Ren, S., \& Sun, J.. Deep residual learning for image recognition. 2016. CVPR.}
    \footnote{Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... \& Polosukhin, I.. Attention is all you need. 2017. NIPS.}
    
    \item 电池机理相关
    \footnote{Yihuan, L., Kang, L., \& James, Y. U.. Estimation approaches for states of charge and health of lithium-ion battery. 2021. Power Generation Technology.}
    \footnote{Bockrath, S., \& Pruckner, M.. Generalized State of Health Estimation Approach based on Neural Networks for Various Lithium-Ion Battery Chemistries. 2023. ACM e-Energy.}
    \footnote{Zhu, J., Wang, Y., Huang, Y., Bhushan Gopaluni, R., Cao, Y., Heere, M., ... \& Ehrenberg, H.. Data-driven capacity estimation of commercial lithium-ion batteries from voltage relaxation. 2022. Nature communications.}
    \footnote{Jia, X., Zhang, C., Li, Y., Zou, C., \& Cai, X.. Knee-Point-Conscious Battery Aging Trajectory Prediction Based on Physics-Guided Machine Learning. 2023. TTE.}
    \footnote{Attia, P. M., Grover, A., Jin, N., Severson, K. A., Markov, T. M., Liao, Y. H., ... \& Chueh, W. C.. Closed-loop optimization of fast-charging protocols for batteries with machine learning. 2020. Nature.}

    \item 迁移学习相关
    \footnote{Shen, L., Li, J., Meng, L., Zhu, L., \& Shen, H. T.. Transfer Learning-based State of Charge and State of Health Estimation for Li-ion Batteries: A Review. 2023. TTE.}
    \footnote{Yihuan Li, Kang Li, Xuan Liu, Yanxia Wang, \& Li Zhang. Lithium-ion battery capacity estimation—a pruned convolutional neural network approach assisted with transfer learning. 2021. Applied Energy.}
    \footnote{Wang, F., Zhao, Z., Zhai, Z., Guo, Y., Xi, H., Wang, S., \& Chen, X.. Feature disentanglement and tendency retainment with domain adaptation for Lithium-ion battery capacity estimation. 2023. Reliability Engineering \& System Safety.}
    \footnote{翟智, 王福金, 邸一, 马珮羽, 赵志斌, \& 陈雪峰.. 基于分层对齐迁移学习的锂离子电池容量估计. 2023. 储能科学与技术.}
    
\end{itemize}
\end{frame}

\begin{frame}
  \begin{itemize}
    \item 贝叶斯深度学习相关
    \footnote{Damianou, A., \& Lawrence, N. D.. Deep gaussian processes. 2013. AISTATS.}
    \footnote{Kendall, A., \& Gal, Y.. What uncertainties do we need in bayesian deep learning for computer vision?. 2017. NIPS.}
    \footnote{Gal, Y., \& Ghahramani, Z.. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. 2016. ICML.}
    \footnote{Gal, Y., Hron, J., \& Kendall, A.. Concrete dropout. 2017. NIPS.}
    \footnote{Jospin, L. V., Laga, H., Boussaid, F., Buntine, W., \& Bennamoun, M.. Hands-on Bayesian neural networks—A tutorial for deep learning users. 2022. CIM.}
    \footnote{Lin, Y. H., \& Li, G. H.. A Bayesian deep learning framework for RUL prediction incorporating uncertainty quantification and calibration. 2022. TII.}
    \item 图神经网络相关
    \footnote{Li, T., Zhou, Z., Li, S., Sun, C., Yan, R., \& Chen, X.. The emerging graph neural networks for intelligent fault diagnostics and prognostics: A guideline and a benchmark study. 2022. MSSP.}
    \footnote{Wang, Y., Xu, Y., Yang, J., Wu, M., Li, X., Xie, L., \& Chen, Z.. Fully-Connected Spatial-Temporal Graph for Multivariate Time Series Data. 2023. AAAI.}
    \item 深度学习中的难例（hard sample）相关
    \footnote{Jia, Y., Gao, J., Huang, W., Yuan, Y., \& Wang, Q.. Exploring Hard Samples in Multi-View for Few-Shot Remote Sensing Scene Classification. 2023. TRGS.}
    \footnote{Cui, P., Zhang, D., Deng, Z., Dong, Y., \& Zhu, J.. Learning Sample Difficulty from Pre-trained Models for Reliable Prediction. 2023. arXiv.}
  \end{itemize}
\end{frame}

\section{代码实现}

\begin{frame}
  \begin{itemize}
    \item （Dataset，DataLoader）锂离子电池数据集整理与数据预处理 \\ \href{https://github.com/hilinxinhui/lib_ds_toolkits}{https://github.com/hilinxinhui/lib\_ds\_toolkits}
    \item （RUL）自回归-卷积神经网络-长短期神经网络（ST dependencies）框架 \\ \href{https://github.com/hilinxinhui/auto-cnn-lstm}{https://github.com/hilinxinhui/auto-cnn-lstm}
    \item （SOH）时序-传感器（ST dependencies）双分支Transformer框架 \\ \href{https://github.com/hilinxinhui/dast.git}{https://github.com/hilinxinhui/dast.git}
    \item （RUL，工况）基于Transformer的多任务框架 \\ \href{https://github.com/hilinxinhui/multi_task_lib/tree/main}{https://github.com/hilinxinhui/multi\_task\_lib/tree/main}
    \item （RUL，工况）基于Transformer的多任务框架（改进位置编码，引入贝叶斯方法修正任务损失函数系数） \\ \href{https://github.com/hilinxinhui/multi_task_lib/tree/dev}{https://github.com/hilinxinhui/multi\_task\_lib/tree/dev}
    \item （SOH）层次迁移学习-通道注意力框架 \\ \href{https://github.com/hilinxinhui/tl_lib_phm.git}{https://github.com/hilinxinhui/tl\_lib\_phm.git}
    \item （SOH）全连接图神经网络（FCGNN for DEDT）框架 \\ \href{https://github.com/hilinxinhui/gnn_lib_phm}{https://github.com/hilinxinhui/gnn\_lib\_phm}
  \end{itemize}
\end{frame}

\section{未来工作}

\begin{frame}
\begin{itemize}
  \item 贝叶斯深度学习 \\ 模型估计/预测结果的不确定性估计、模型幻觉、硬样本/难例判定
  \item 迁移学习 \\ 多工况混合情形的迁移学习、图迁移学习
  \item 模型压缩 \\ 知识蒸馏、agent注意力机制、全连接图神经网络“剪枝”
  \item 电池组健康状态估计和剩余寿命预测 \\ 电池组数据集缺乏、电池组健康状态/剩余寿命定义模糊
  \item 电池荷电状态估计（SOC）、电化学阻抗谱（EIS）预测和健康状态-荷电状态联合估计框架
  \item ......
\end{itemize}
\end{frame}

\end{document}